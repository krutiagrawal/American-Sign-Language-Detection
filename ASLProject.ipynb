{
 "cells": [
  {
   "cell_type": "code",
   "id": "9328fb79-427d-4b55-8e60-815ab6f42f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T12:41:39.159058Z",
     "start_time": "2024-10-30T12:41:39.134174Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "4798a60a-35d7-411c-ab24-39d063f39334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T12:41:39.178459Z",
     "start_time": "2024-10-30T12:41:39.172031Z"
    }
   },
   "source": [
    "# Defining paths\n",
    "train_dir = r'C:\\Users\\Kruti Agrawal\\Desktop\\Projects\\ASL_detection\\ASL_detection\\asl_alphabet_train\\asl_alphabet_train'"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "e5f485cb-5709-4701-9fc2-a77b4a3eb335",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T12:44:54.256434Z",
     "start_time": "2024-10-30T12:41:39.276022Z"
    }
   },
   "source": [
    "# Loading data\n",
    "def load_data(train_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_labels = os.listdir(train_dir)\n",
    "    class_labels.sort()  \n",
    "\n",
    "    for label in class_labels:\n",
    "        class_path = os.path.join(train_dir, label)\n",
    "        for image_file in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            images.append(image)\n",
    "            labels.append(class_labels.index(label))  \n",
    "\n",
    "    return np.array(images), np.array(labels), class_labels\n",
    "\n",
    "images, labels, class_labels = load_data(train_dir)"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "90e041c0-a9c1-445e-9615-f60d7cad4271",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T12:44:54.741456Z",
     "start_time": "2024-10-30T12:44:54.415927Z"
    }
   },
   "source": "images = images.astype('float32') / 255.0",
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 38.9 GiB for an array with shape (87000, 200, 200, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[42], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Normalize images\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m images \u001B[38;5;241m=\u001B[39m \u001B[43mimages\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfloat32\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255.0\u001B[39m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 38.9 GiB for an array with shape (87000, 200, 200, 3) and data type float32"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "ee45cb52-50a6-4b97-b804-814b55bd2d82",
   "metadata": {},
   "source": [
    "# Converting labels to categorical\n",
    "labels = to_categorical(labels, num_classes=len(class_labels))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff9d687e-2e71-4f8c-a3e9-038680b10e45",
   "metadata": {},
   "source": [
    "# Splitting data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1cbdc86c-ef63-4422-9b2f-5c3967c3bb79",
   "metadata": {},
   "source": [
    "# Creating an image data generator with augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a86df5fc-5d94-4d5f-be38-83b821f43037",
   "metadata": {},
   "source": [
    "# Fitting the generator on training data\n",
    "datagen.fit(X_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ff5395a-7d08-423c-a843-0f8554d2ec7d",
   "metadata": {},
   "source": [
    "# Loadong MobileNetV2 as the base model\n",
    "base_model = MobileNetV2(input_shape=(64, 64, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca23db2e-5704-41f3-bfa8-6cac3de8f345",
   "metadata": {},
   "source": [
    "# Adding custom layers on top of MobileNetV2\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),  # Additional dense layer\n",
    "    Dropout(0.3),\n",
    "    Dense(len(class_labels), activation='softmax')\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c45803b6-6521-40f6-ae53-8f03d92a1872",
   "metadata": {},
   "source": [
    "#for layer in base_model.layers[-20:]: \n",
    "    #layer.trainable = True\n",
    "    \n",
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ad08dd5-faba-4fc9-8443-0e5e0745a7e3",
   "metadata": {},
   "source": [
    "# Defining a learning rate reducer\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47a3e874-3a8b-4840-b76f-1e022db04cc2",
   "metadata": {},
   "source": [
    "# Training the model with the data generator and callbacks\n",
    "model.fit(datagen.flow(X_train, y_train, batch_size=32), \n",
    "          validation_data=(X_val, y_val), \n",
    "          epochs=50,  \n",
    "          callbacks=[lr_reducer])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0095c933-11c5-407c-940e-b9771139881a",
   "metadata": {},
   "source": [
    "# Predictions on validation data\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c750bacf-277b-46dd-b576-3bdd1930833a",
   "metadata": {},
   "source": [
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0f7d15df-b6a0-43e6-8130-594a8941c026",
   "metadata": {},
   "source": [
    "# Classification report\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_labels))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e868c4f-17b8-4223-945a-a15e7951ac3e",
   "metadata": {},
   "source": [
    "# Saving the trained model for later use in Streamlit\n",
    "model.save('asl_model.h5')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9475e25d-85e0-4691-8997-38b754b44803",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
